%
% 1_prinzip_1d.tex -- Das Prinzip der Methode der finiten Elemente in einer Dimension
%
% (c) 2024 Flurin Brechbühler, OST - Ostschweizer Fachhochschule Rapperswil
%
% !TEX root = ../../buch.tex
% !TEX encoding = UTF-8
%
\section{Prinzip in einer Dimension\label{fem:1d}}
\kopfrechts{Prinzip 1D}

Das Vorgehen zum Lösen eines Problems mit der Methode der finiten Elemente kann in fünf Schritte unterteilt werden:
\begin{enumerate}
    \item Bilden der schwachen Form
    \item Diskretisieren
    \item Aufstellen der Matrix
    \item Codieren der Anfangsbedingungen
    \item Lösen des Gleichungssystems bzw. Invertieren der Matrix
\end{enumerate}

Um die einzelnen Schritte darzustellen, betrachten wir das Problem
\begin{equation}
    u''(x) = f(x)
    \label{fem:1d:poisson_gleichung},
\end{equation}
was der Poisson-Gleichung entspricht. 
Diese findet in vielen Teilen der Physik Anwendung und ist gleichzeitig ein gutes, einfaches Beispiel einer mit der FEM lösbaren Differenzialgleichung.


\subsection{Bilden der schwachen Form}
Um das Problem in die schwache Form zu bringen, wird über beide Seiten der Poisson-Gleichung \ref{fem:1d:poisson_gleichung} integriert.
Zuvor werden jedoch beide Seiten mit der Testfunktion $ v(x) $ multipliziert.
Diese wird definiert als eine beliebige Funktion $ v \colon \mathbb{R} \rightarrow \mathbb{R} $.
Die resultierende Gleichung
\begin{equation}
    \int(u''(x) \cdot v(x)) \diff x = \int(f(x) \cdot v(x)) \diff x \myforall v(x)
    \label{fem:1d:schwache_form}
\end{equation}
sollte einem bekannt vorkommen: Sie entsteht auch beim Herleiten der ersten Variation.
Im Kapitel \ref{buch:variation:section:fundamentallemma} zum Fundamentallemma wird bewiesen, dass die beiden Ausdrücke \ref{fem:1d:poisson_gleichung} und \ref{fem:1d:schwache_form} gleichwertig sind.

Durch partielles Integrieren der linken Seite kann die Ordnung der Differenzialgleichung um eins verringert werden:
\begin{align}
    \int f(x) \cdot v(x) \diff x &= \int u''(x) \cdot v(x) \diff x \\
                                 &= \left[ u'(x) \cdot v(x) \right]_{x_1}^{x_2} - \int u'(x) \cdot v'(x) \diff x \\
                                 &= - \int u'(x) \cdot v'(x) \diff x \\
                                 &= - \Phi(u, v)
\end{align}
wobei der Term
\begin{equation}
    \left[ u'(x) \cdot v(x) \right]_{x_1}^{x_2}
\end{equation}
Null ist, wenn die Funktion $u'(x)$ die Randbedingung
\begin{equation}
    u'(x_1) = u'(x_2) = 0
\end{equation}
erfüllt. 

Der erhaltene Term wird als $-\Phi(u, v)$ abgekürzt.
Dieser Weg kann, abhängig von der ursprünglichen Differenzialgleichung, anders sein.
Das häufigste Vorgehen dabei --- das partielle Ableiten der rechten Seite --- wurde jedoch hier gezeigt.
Ziel ist es, die Ordnung der Differenzialgleichung möglichst stark zu verkleinern, da so Ansätze kleinerer Ordnung verwendet werden können.
Dies spart Rechenleistung.


\subsection{Diskretisieren\label{fem:1d:diskretisieren}}
Ziel des Diskretisierens ist es, das unendlichdimensionale Problem in ein endlichdimensionales umzuwandeln.
Dazu werden die ursprünglichen Funktionen $u(x)$, $f(x)$ und $v(x)$ an $N$ verschiedenen Punkten $x_n$ abgetastet.
Die resultierenden Knotenvariablen
\begin{equation}
    u_n = u(x_n) 
    \text{,} \quad
    f_n = f(x_n)
    \quad \text{und} \quad
    v_n = v(x_n)
\end{equation}
können dann mit einer Interpolationsfunktion mit schmalem Träger
\begin{equation}
    a_n(x) = \left\{ \begin{array}{ll}
        1
            & \text{für} \quad x = x_n \\
        a(x) \in (0, 1) 
            & \text{für} \quad x_{n-1} < x < x_n \quad \text{und} \quad x_n < x < x_{n+1} \\
        0
            & \text{sonst} 
    \end{array} \right.
\end{equation}
multipliziert werden und zu einer durch $N$ Werte parametrisierten stetigen Funktion zusammengesetzt werden:
\begin{equation}
    u(x) \approx \sum_{n=0}^{N}{u_n \cdot a_n(x)} 
    \text{,} \quad
    f(x) \approx \sum_{n=0}^{N}{f_n \cdot a_n(x)} 
    \quad \text{und} \quad
    v(x) \approx \sum_{n=0}^{N}{v_n \cdot a_n(x)}.
\end{equation}

Für die Interpolationsfunktion $a(x)$ können verschiedene Ansätze gewählt werden:
\begin{itemize}
    \item[\textbf{linear:}] 
        Einfach zu rechnen und zu verstehen, jedoch ist die erste Ableitung unstetig und die zweite Ableitung Null.
        Dementsprechend kann dieser Ansatz nur verwendet werden, wenn keine zweiten Ableitungen im vereinfachten Problem vorkommen.
    \item[\textbf{quadratisch:}]
        Ist die Ordnung des Problems um eins zu hoch, um den linearen Ansatz zu verwenden, kann der quadratische Ansatz eingesetzt werden.
        Die ersten Ableitungen sind jedoch nach wie vor unstetig.
    \item[\textbf{kubisch:}]  
        Der kubische Ansatz hat sehr gute Eigenschaften - er besitzt eine stetige erste Ableitung sowie zweite und dritte Ableitungen ungleich Null. 
        Zudem bietet er die Möglichkeit, die ersten Ableitungen an den Stützpunkten frei zu wählen.
        Dies wird später zum Berücksichtigen der Anfangsbedingungen hilfreich sein.
\end{itemize}

\subsubsection{Linearer Ansatz}
\input{papers/fem/fig/linearer_ansatz_entwurf.tex} % TODO: Widerholende Formfunktionen und Summe deren als Graphen zeigen
Der lineare Ansatz verwendet die in Abb. \ref{fem:1d:abb:linear} gezeigten linearen Funktionen
\begin{equation}
    a_n(x) = \left\{ \begin{array}{ll}
        1+\frac{x-x_n}{x_n - x_{n-1}} 
            & \text{für} \quad x_{n-1} < x < x_n \\
        1-\frac{x-x_n}{x_{n+1} - x_n} 
            & \text{für} \quad x_n \leq x < x_{n+1} \\
        0
            & \text{sonst}
    \end{array} \right..
\end{equation}

Die Formfunktionen des Linearen Ansatzes können mit dem Ansatz 
\begin{equation}
    a(x) = c_1x + c_0
\end{equation}
und den zu erfüllenden Bedingungen
\begin{equation}
        a(x_n) = 1 
        \quad \text{und} \quad
        a(x_{n-1}) = a(x_{n+1}) = 0
\end{equation}
hergeleitet werden.

\subsubsection{Quadratischer Ansatz}
\input{papers/fem/fig/quadratischer_ansatz.tex} % TODO: Widerholende Formfunktionen und Summe deren als Graphen zeigen
Für das Interpolieren mit dem quadratischen Ansatz muss das Vorgehen leicht angepasst werden. 
Während beim linearen Ansatz für jeden Knoten dieselbe Formfunktion verwendet wurde, wird beim quadratischen Ansatz zwischen zwei Funktionen abgewechselt.

Die in Abb. \ref{fem:1d:abb:quadratisch} gezeigten Formfunktionen lauten
\begin{equation}
    a_n(x) = \left\{ \begin{array}{ll}
        \frac{1}{2(x_{n} - x_{n-1})^2} \cdot x^2 + \frac{3}{2 (x_{n} - x_{n-1})} \cdot x + 1  
            & \text{für} \quad x_{n-1} \leq x < x_n \\
        \frac{1}{2(x_{n+1} - x_{n})^2} \cdot x^2 - \frac{3}{2 (x_{n+1} - x_{n})} \cdot x + 1
            & \text{für} \quad x_n < x \leq x_{n+1} \\
        0
            & \text{sonst}
    \end{array} \right.
\end{equation}
für gerade $n$ und
\begin{equation}
    a_n(x) = \left\{ \begin{array}{ll}
        -\frac{1}{(x_n - x_{n-1})^2} x^2 + 1 
            & \text{für} \quad x_{n-1} < x < x_n \\
        -\frac{1}{(x_{n+1} - x_n)^2} x^2 + 1 
            & \text{für} \quad x_n \leq x < x_{n+1} \\
        0 
            & \text{sonst}
    \end{array} \right.
\end{equation}
für ungerade $n$.

Diese Formfunktionen können mit dem Ansatz 
\begin{equation}
    a_n(x) = c_2x^2 + c_1x + c_0
\end{equation}
und den Bedingungen 
\begin{equation}
        a_n(x_n) = 1 
        \quad \text{und} \quad 
        a(x_{n-1}) = a(x_{n+1}) = 0
\end{equation}
für gerade $n$ bzw.
\begin{equation}
        a_n(x_n) = 1 
        \quad \text{und} \quad
        a(x_{n-1}) = a(x_{n+1}) = 0
\end{equation}
für ungerade $n$ hergeleitet werden.

\subsubsection{Kubischer Ansatz}
\input{papers/fem/fig/kubischer_ansatz.tex} % TODO: Widerholende Formfunktionen und Summe deren als Graphen zeigen
Der kubische Ansatz erbringt die Möglichkeit, den Wert der Funktion wie auch den Wert der Ableitung an den Stützstellen frei zu wählen.
Dafür muss der Ansatz etwas erweitert werden:
\begin{equation}
    u(x) \approx \sum_{n}{u_n \cdot a_n(x)} \rightarrow u(x) \approx \sum_{n}{u_n \cdot a_n(x) + u'_n \cdot b_n(x)}.
\end{equation}

Die Formfunktionen, dargestellt in Abb. \ref{fem:1d:abb:kubisch}, 
\begin{equation}
    a(x) = \left\{ \begin{array}{ll}
        - \frac{2}{(x_n - x_{n-1})^3} \cdot x^3 + \frac{3}{(x_n - x_{n-1})^2} \cdot x^2 + 1 
            & \text{für} \quad x_{n-1} < x < x_n \\
        \frac{2}{(x_{n+1} - x_n)^3} \cdot x^3 + \frac{3}{(x_{n+1} - x_n)^2} \cdot x^2 + 1 
            & \text{für} \quad x_n \leq x < x_{n+1} \\
        0
            & \text{sonst}
    \end{array} \right.
\end{equation}
und
\begin{equation}
    b(x) = \left\{ \begin{array}{ll}
        \frac{1}{(x_n - x_{n-1})^2} \cdot x^3 + \frac{2}{x_n - x_{n-1}} \cdot x^2 + x 
            & \text{für} \quad x_{n-1} < x < x_n \\
        \frac{1}{(x_{n+1} - x_n)^2} \cdot x^3 - \frac{2}{x_{n+1} - x_n} \cdot x^2 + x 
            & \text{für} \quad x_n \leq x < x_{n+1} \\
        0
            & \text{sonst}
    \end{array} \right.
\end{equation}
können mit dem Ansatz
\begin{equation}
    a(x) = c_3x^3 + c_2x^2 + c_1x + c_0 
    \quad \text{bzw.} \quad
    b(x) = d_3x^3 + d_2x^2 + d_1x + d_0
\end{equation}
und den Bedingungen 
\begin{equation}
        a(x_n) = 1 
        \quad \text{und} \quad
        a(x_{n-1}) = a(x_{n+1}) = 0 
        \quad \text{sowie} \quad
        a'(x_{n-1}) = a'(x_n) = a'(x_{n+1}) = 0
\end{equation}
und
\begin{equation}
        b'(x_n) = 1 
        \quad \text{und} \quad
        b'(x_{n-1}) = b'(x_{n+1}) = 0 
        \quad \text{sowie} \quad
        b(x_{n-1}) = b(x_n) = b(x_{n+1}) = 0
\end{equation}
hergeleitet werden.


\subsection{Erstellen der Matrix\label{fem:1d:matrix_erstellen}}
Um das Problem als Matrixgleichung zu repräsentieren, muss zunächst die Differenzialgleichung in der schwachen Form in ein lineares Gleichungssystem überführt werden.
Mit den Approximationen 
\begin{align}
    u(x) &\approx \sum_i u_i \cdot a_i(x) \\
    f(x) &\approx \sum_i f_i \cdot a_i(x) \\
    v(x) &\approx \sum_i v_i \cdot a_i(x)
\end{align}
aus der Diskretisierung kann die schwache Form der Differenzialgleichung 
\begin{equation}
    - \int u'(x) \cdot v'(x) \diff x = \int f(x) \cdot v(x) \diff x
\end{equation}
als
\begin{equation}
    - \int \biggl(\sum_i u_j \cdot a'_j(x)\biggr) \biggl(\sum_j v_i \cdot a'_i(x)\biggr) \diff x 
    = \int \biggl(\sum_i f_j \cdot a_j(x) \biggr) \biggl(\sum_j v_i \cdot a_i(x) \biggr) \diff x 
    \myforall v_i
\end{equation}
geschrieben werden.
Diese Gleichung kann zu
\begin{equation}
    - \int \sum_j u_j \cdot a'_j \cdot a'_i(x) \diff x = \int \sum_j f_j \cdot a_j(x) \cdot a_i(x) \diff x \myforall i
\end{equation}
vereinfacht werden.
Dabei wird die Menge der Testfunktionen reduziert.
Anstelle, dass alle Testfunktionen mit beliebig breitem Träger berücksichtigt werden, werden nur die $N$ verschiedenen Testfunktionen mit schmalstmöglichem Träger verwendet.
Da alle anderen Testfunktionen aus diesen ``zusammengebaut'' werden können, ist die Gleichung auch für diese erfüllt.
Diese Vereinfachung ermöglicht es, die Summen aus den Integralen zu bringen und die Gleichung als
\begin{equation}
    - \sum_j u_j \int a'_j \cdot a'_i(x) \diff x = \sum_j f_j \int a_j(x) \cdot a_i(x) \diff x \myforall i \label{papers:fem:prinzip1d:finale_gleichung}
\end{equation}
zu schreiben.
Übrig bleibt also, da die Integrale ausgewertet werden können, ein lineares Gleichungssystem mit $N$ Unbekannten $u_j$ und $N$ Gleichungen (eine pro $i$). 

Das erhaltene Gleichungssystem lässt sich nun sehr gut als Matrizen, bei denen die Zeilen über $i$ und die Spalten über $j$ iterieren, darstellen:
\begin{multline}
    \left(
        \begin{matrix}
            \int a'_1(x) \cdot a'_1 \diff x & \hdots & a'_N(x) \cdot a'_1(x) \diff x \\
            \vdots                          & \ddots & \vdots                        \\
            \int a'_1(x) \cdot a'_N \diff x & \hdots & a'_N(x) \cdot a'_N(x) \diff x \\
        \end{matrix}
    \right)
    \left(
        \begin{matrix}
            u_1 \\
            \vdots \\
            u_N
        \end{matrix}
    \right) \\
    = \\
    \left(
        \begin{matrix}
            \int a_1(x) \cdot a_1 \diff x & \hdots & a_N(x) \cdot a_1(x) \diff x \\
            \vdots                        & \ddots & \vdots                      \\
            \int a_1(x) \cdot a_N \diff x & \hdots & a_N(x) \cdot a_N(x) \diff x \\
        \end{matrix}
    \right)
    \left(
        \begin{matrix}
            f_1 \\
            \vdots \\
            f_N
        \end{matrix}
    \right),
\end{multline}
was kompakt als
\begin{equation}
    \mathbf{M}\vec{f} = -\mathbf{L}\vec{u}
\end{equation}
geschrieben wird.
Auch gängig ist das Zusammenfassen von $\mathbf{M}\vec{f}$ zu $\vec{b}$, was zur Gleichung
\begin{equation}
    \mathbf{L}\vec{u} + \vec{b} = 0
\end{equation}
führt.

Diese Matrizen werden aufgrund des schmalen Trägers der Funktionen $a_n(x)$ (sowie $b_n(x)$ beim kubischen Ansatz) sehr schwach besetzt sein, da viele der Integrale
\begin{equation}
    \int a_i(x) \cdot a_j \diff x \quad 
    \text{ bzw. } 
    \quad \int a'_i(x) \cdot a'_j \diff x 
\end{equation}
Null sein werden.
Von Null verschieden sind nur die Einträge, deren zugehörige Datenpunkte nebeneinander liegen.
Zudem sind sie symmetrisch und positiv definit, da es keine Rolle spielt in welcher Reihenfolge man die Testfunktionen multipliziert.

\subsubsection{Kubischer Ansatz}
Auch hier verlangt der kubische Ansatz mit seinen zwei Funktionen pro Datenpunkt eine leichte Anpassung: 
\begin{itemize}
    \item Die Vektoren $\vec{b}$ und $\vec{f}$ werden für die gleiche Menge Datenpunkte doppelt so viele Elemente enthalten.
          Dies aus dem Grund, dass für jeden Wert $u_i$ ein zweiter Wert $u'_i$ dazukommt.
    \item Folglich wird die Matrix $\mathbf{L}$ doppelt so viele Zeilen und Spalten enthalten. 
\end{itemize}


\subsection{Codieren der Anfangsbedingungen\label{fem:1d:anfangsbedingungen}}
Wir betrachten das Gleichungssystem in der Form $\mathbf{L}\vec{u} + \vec{b} = 0$. 
Die Zeilen und Spalten der Matrix $\mathbf{L}$ codieren dabei die Beziehungen zwischen den einzelnen Elementen.
Der $k$-ten Zeile kann zum Beispiel entnommen werden, welche anderen Elemente das $k$-te Element berühren. 
Sollte nun also $u_k$ gegeben sein, so wird der $k$-te Wert der $k$-ten Zeile eins gesetzt, während die übrigen Elemente der Zeile alle Null gesetzt werden.
Die $k$-te Zeile stellt folglich die Gleichung 
\begin{equation}
    1 \cdot u_n + b_n = 0
\end{equation}
dar. 
Es kann nun also durch Setzen von $b_n = -u_n$ die Anfangsbedingung codiert werden.

Nun ist aber $\mathbf{L}$ nicht mehr symmetrisch, was Effizienzeinbussen beim Invertieren dieser zur Folge hätte.
Das nächste Ziel ist also, auch die $k$-te Spalte so weit zu bringen, dass nur das $k$-te Element ungleich Null ist.
Um dies zu erreichen, wird vor dem Nullsetzen der Spalte zu jedem Element von $\vec{b}$ ein Korrekturterm addiert.
Der zu $b_k$ zu addierende Term berechnet sich als
\begin{equation}
    l_{ik} \cdot u_k.
\end{equation}
Bei homogenen Anfangsbedingungen ist dieser Term offensichtlich Null (da $u_k = 0$), was diese besonders einfach zu codieren macht.

\subsubsection{Codieren von gegebenen Ableitungen}
Da der lineare wie auch der quadratische Ansatz keinen direkten Weg bietet, die Ableitungen der Funktion $u(x)$ zu bestimmen, muss mit einem Trick Abhilfe geschafft werden: 
Die Anfangsbedingung
\begin{equation}
    u'(0) = 0
\end{equation}
kann näherungsweise als 
\begin{equation}
    u_0 = u_1
\end{equation}
codiert werden. 

Der kubische Ansatz hat dabei einen klaren Vorteil: 
Der gegebene Wert der Ableitung kann direkt als 
\begin{equation}
    u'_n = u'(0)
\end{equation}
codiert werden.


\subsection{Invertieren der Matrix\label{fem:1d:matrix_invertieren}}
Zur Lösung der Poisson-Gleichung muss nun also ``nur'' noch die Matrix $\mathbf{L}$ invertiert werden.
Das Resultat in Form des Spaltenvektors $\vec{u}$, enthaltend die Stützstellen der Lösungsfunktion, lässt sich dann als
\begin{equation}
    \vec{u} = - \mathbf{L}^{-1}\mathbf{M}\vec{f} = - \mathbf{L}^{-1}\vec{b}
\end{equation}
berechnen.

Zum Invertieren der Matrix gibt es optimierte Zerlegungsalgorithmen wie SuperLU, Choldmod oder Mumps, die die schwache Besetzung der Matrizen ausnützen, um diese effizient zu zerlegen.
Nach dem Zerlegen ist das Invertieren stark vereinfacht.
Weiter bieten sich iterative Vorgehen wie die Methode des konjugierten Gradienten oder GMRES an.
Auch diese können aus der schwachen Besetzung der Matrix Nutzen ziehen.
